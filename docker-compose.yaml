version: '3.8'

services:
  vllm:
    container_name: c3-vllm
    image: ghcr.io/comput3ai/c3-vllm:latest
    env_file: .env
    volumes:
      - ./models:/models
    ports:
      - "${PORT:-8080}:8000"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    ipc: host
    shm_size: 32gb
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65535
        hard: 65535
    restart: unless-stopped